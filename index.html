<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8"/>
  <meta name="google-site-verification" content="nBo2kHCn1fTJSbRpR7mxHWQ_sIphRBYKS4sAjxqb8IY" />

  <meta name="Author" content="Ruikun Luo" />
  <meta name="Author" content="Ruikun" />

  <title>Ruikun Luo - University of Michigan</title>

  <!-- boostrap -->
  <script src="https://code.jquery.com/jquery.js"></script>
  <script src="libs/bootstrap-3.3.7-dist/js/bootstrap.min.js"></script>
  <link href="libs/bootstrap-3.3.7-dist/css/bootstrap.min.css" rel="stylesheet"/>
  
  <!-- gt icon -->
  <link rel="shortcut icon" href="https://robotics.umich.edu/wp-content/uploads/2018/12/robotics-social-blue.jpg" type="image/vnd.microsoft.icon" />
  
  <!-- icons -->
  <link rel="stylesheet" href="libs/font-awesome-4.6.3/css/font-awesome.min.css"/>
  <link rel="stylesheet" href="libs/academicons-1.7.0/css/academicons.css"/>
  
  <!-- custom css -->
  <link href="custom.css" rel="stylesheet">
</head>

<body>

<!-- nav bar : name / home / cv -->
<nav class="navbar navbar-default" role="navigation">
  <div class="container-fluid">
  <div class="navbar-header">
    <a class="navbar-brand" href="index.html">Ruikun Luo</a>
  </div>
  <div>
    <ul class="nav navbar-nav">
      <li class="active"><a href="index.html">Home</a></li>
      <li><a href="#news">News</a></li>
      <li><a href="#research">Research</a></li>
      <li><a href="#publications">Publications</a></li>
      <li><a href="#service">Service</a></li>
      <li><a href="#award">Awards</a></li>
      <li><a href="files/ruikunl_cv.pdf">CV</a></li>
    </ul>
  </div>
  </div>
</nav>

<!-- intro -->
<div class="container">
  <div class="jumbotron">
    
    <!-- photo and contact -->
    <div class="row">
      <div class="col-md-4">
        <br/>
        <img class="img-thumbnail img-responsive" src="images/ruikun-head-shot.jpg">
      </div>
      <div class="col-md-8">
        <h2>Ruikun Luo</h2>
        <p style="font-size:16px">
          Ph.D. student in Robotics, University of Michigan, Ann Arbor
          <br/>
        </p>
        
        <p>
          <a href="mailto:ruikunl@umich.edu" title="Email"><i class="fa fa-envelope" style="font-size:20px"></i> Email</a>,
          <a href="https://scholar.google.com/citations?user=QCb0yIcAAAAJ&hl=en&oi=ao" title="Google Scholar"><i class="ai ai-google-scholar" style="color:#4885ED;font-size:20px"></i>Google Scholar</a>,
          <a href="https://github.com/ruikunl" title="Github"><i class="fa fa-github" style="color:#000000;font-size:20px"></i> Github</a>,
          <a href="https://www.linkedin.com/in/ruikun-luo/" title="Linkedin"><i class="fa fa-linkedin-square" style="color:#007BB6;font-size:20px"></i> Linkedin</a>
        </p>
        
        <!-- bio -->
        <p>
          I'm now a 6th year Ph.D. student in Robotics Institute at University of Michigan, working with professor <a href="https://ioe.engin.umich.edu/people/xi-jessie-yang/">Xi Jessie Yang</a> at the <a href="http://icrl.engin.umich.edu/index.php/xi-jessie-yang/">Interaction & Collaboration Research Lab (ICRL)</a>.
        </p>
        <p>
          I received a B.E. in Mechanical Engeering and Automation from Tsinghua University in 2012 and a M.S. in Mechanical Engineering from Carnegie Mellon University in 2014, where I worked with professor <a href="http://www.cs.cmu.edu/~sycara/">Katia Sycara</a> and professor <a href="https://me.stonybrook.edu/people/faculty/Chakraborty_Nilanjan.html">Nilanjan Chakraborty</a>.
          Prior to joining ICRL, I used to work with professor <a href="http://web.eecs.umich.edu/~dmitryb/">Dmitry Berenson</a> at the <a href="http://arm.eecs.umich.edu/#">ARM Lab</a>.
        </p>
        <p>
          My research interest lies in the intersection of machine learning, robotics and human factors.
          My current research interest is human robot/AI interaction/collaboration.
          My research goal is to study how to use machine learning to understand human, how robot makes decisions based on the interred behavior of human and how to make human understand robot/AI.
        </p>
        <!--<p style="color:#909090;font-style:italic">
          I'm looking for full-time research scientist or engineer positions start at mid 2018 in US, with special interests in SLAM, mapping and motion planning. Please refer to my <a href="files/jing_cv.pdf">CV</a>.-->
        </p>
      </div>
    </div>
  </div>
</div>


<!-- news -->
<div class="container">
  <h2 id="news">News</h2>
  <hr/>
  <div class="row">
    <div class="col-md-12">
      <ul>
        <li><span style="font-weight:bold">2019.10 - </span>University of Michigan reports our research on interactive robot docent in the museum.  <a href="https://arts.umich.edu/news-features/u-m-museum-of-art-brings-robots-to-the-art-world/">Check the news!</a>.  </li>
        <li><span style="font-weight:bold">2019.08 - </span>I received the <a href="https://www.hfes.org/blogs/lindsey-kim/2019/08/15/2019-student-presenter-awards-and-travel-awards">2019 HFES Student Presenter Award</a>.  </li>
        <li><span style="font-weight:bold">2019.05 - </span>Two papers accepted in Human Factors and Ergonomics Society's 2019 International Annual Meeting! <a href="files/HFES2019_Bayesion_inference_workload_estimation.pdf">Toward Real-time Assessment of Workload: A Bayesian Inference Approach</a> and <a href="files/HFES2019_Explanation_AI.pdf">Enhancing Transparency in Human-autonomy Teaming via the Option-centric Rationale Display</a>.</li>
        <!--<li><span style="font-weight:bold">2016.04 - </span>Our paper <a href="files/Dong16rss.pdf">Gaussian Process Motion Planner 2</a> has been accepted in <a href="http://www.roboticsconference.org/">RSS 2016</a>!</li>-->
      </ul>
    </div>
  </div>
</div>

<br/>

<!-- publication -->
<div class="container">
  <h2 id="research">Research Projects</h2>
  <hr/>

  <h3>Mutually-Adaptive Shared Control between Human Operators and Autonomy in Ground Vehicles</h3>
  <br/>
  
  <!-- arxiv ijrr 2017 -->
  <div class="row">
    <div class="col-md-6">
      <!--<div class="embed-responsive embed-responsive-16by9">-->
        <!--<iframe src="https://www.youtube.com/embed/BgLlLlsKWzI" allowfullscreen></iframe>-->
      <!--</div>-->
      <img class="img-thumbnail img-responsive" src="images/ARC_project.jpg">
    </div>
    <div class="col-md-6">
      <p>
        <!--<em>spatio-temporal 3D reconstruction</em>-->
        <!--<span style="font-style:italic">et al.</span>-->
        Successful shared control between human operators and autonomy in ground vehicles critically relies on a mutual understanding and adaptation.
        Existing haptic shared control schemes, however, do not take full consideration of the human agent. To fill this research gap, we presented a haptic shared control scheme that adapts to a human operator's workload, eyes on road and input torque in real-time.
        We proposed a Bayesian Inference model for assessing human's workload which combined different machine learning models for different features.
      </p>
 			<br/>
      <p>
      <span style="font-weight: bold;">Publication:</span><span style='font-size: 14px;'> (* equal contribution)</span>
      </p>
      <span style='font-size: 14px;'>
      <p>
      [1] <b>R. Luo*</b>, Y. Wang*, Y. Weng, V. Paul, M. J. Brudnak, P. Jayakumar, M. Reed, J. L. Stein, T. Ersal, X. J. Yang, Toward Real-time Assessment of Workload: A Bayesian Inference Approach, in <span style="font-style:italic">HFES</span> 2019. <a href="files/HFES2019_Bayesion_inference_workload_estimation.pdf">[PDF]</a>
      </p>
      <p>
      [2] <b>R. Luo*</b>, Y. Weng*, Y. Wang, P. Jayakumar, M. J. Brudnak, V. Paul, V. R. Desaraju, J. L. Stein, T. Ersal, X. J. Yang, A Workload Adaptive Haptic Shared Control Scheme for Semi-Autonomous Driving. in <span style="font-style:italic">Transactions On Human-Machine Systems</span>. [<em>In Preparation</em>]
      </p>
      </span>
    </div>
  </div>
  
  <br/>

  <h3>Explanable AI: an <em>option-centric rationale</em> approach</h3>
  <br/>
  
  <!-- arxiv ijrr 2017 -->
  <div class="row">
    <div class="col-md-6">
      <img class="img-thumbnail img-responsive" src="images/with_exp_new.PNG">

    </div>
    <div class="col-md-6">
      <p>
        To enhance autonomy transparency, we proposed an <em>option-centric rationale</em> display inspired by the research on design rationale. The display details all the available next actions, the criteria for choosing a particular one and highlight the final recommendation.
        <!--We developed a simulated game <em>Treasure Hunter</em> wherein an human operator and an intelligent assistant worked together to uncover a map for treasures, with or without the display.-->
        Our results showed that by conveying the intelligent assistant's intent and decision-making rationale via the <em>option-centric rationale</em> display, participants had higher trust in the system and calibrated their trust faster.
      </p>


      <br/>

      <p>
      <span style="font-weight: bold;">Publication:</span>
      </p>
      <span style='font-size: 14px;'>
      <p>
      [1] <b>R. Luo</b>, N. Du, K. Y. Huang, X. J. Yang, Enhancing Transparency in Human-autonomy Teaming via the Option-centric Rationale Display, in <span style="font-style:italic">HFES</span> 2019. <a href="files/HFES2019_Explanation_AI.pdf">[PDF]</a>
      </p>
      <p>
      [2] <b>R. Luo</b>, N. Du, K. Y. Huang, X. J. Yang, Enhancing autonomy transparency: an option-centric rationale approach, in <span style="font-style:italic">Journal of Cognitive Engineering and Decision Making</span> 2019. [<em>In Preparation</em>]
      </p>

      </span>
    </div>
  </div>

  <br/>

  <h3>Human-Robot Collaboration in Shared Workspace</h3>
  <br/>
  
  <!-- arxiv ijrr 2017 -->
  <div class="row">
    <div class="col-md-6">
      <!--<iframe width="896" height="672" src="https://www.youtube.com/embed/y9QXJxuG2KI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
      <!--<iframe width="1195" height="672" src="https://www.youtube.com/embed/YvsmWzSFDzM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>-->
      <div class="embed-responsive embed-responsive-16by9">
        <iframe src="https://www.youtube.com/embed/y9QXJxuG2KI" allowfullscreen></iframe>
      </div>
      <div class="embed-responsive embed-responsive-16by9">
        <iframe src="https://www.youtube.com/embed/YvsmWzSFDzM" allowfullscreen></iframe>
      </div>
    </div>
    <div class="col-md-6">
      <p>
    This project focuses on human-robot collaboration in industrial manipulation tasks that take place in a shared workspace. In this setting, we consider both the adaptation of the robot and the adaptation of the human.
      </p>
      <p>
    <b> Robot Adapts to Human:</b>
        Given an observed part of a human's reaching motion, we wish to predict, as quickly as possible, the remainder of the trajectory so that the robot can avoid interference while performing a complimentary task.
    We proposed a two layer framework of Gaussian Mixture Models and an unsupervised online learning algorithm that updates these models with newly-observed trajectories.
    The proposed method can build models on-the-fly and adapt to new people and new motion styles as they emerge which requires no manual labeling.
    We also present two human-robot workspace sharing experiments of varying difficulty where the robot predicts the human's motion every 0.1s.
    The results show that our framework can use human motion predictions to decide on robot motions that avoid the human in real-time applications with high reliability.
      </p>
      <p>
        <b>Human Adapts to Robot:</b>
        In stead of online selecting robot motions, we consider offline motion planning of the robot.
        To be effective for human-robot collaboration a robot should plan its motion so that it is both safe and efficient.
        To achieve this, we propose two factors to consider in the cost function for the robot’s motion planner:
        (1) Avoidance of the workspace previously-occupied by the human, so that the motion is as safe as possible,
        and (2) Consistency of the robot’s motion, so that the motion is as predictable as possible for the human and they can perform their task without focusing undue attention on the robot.
      </p>

      <br/>
      <p>
      <span style="font-weight: bold;">Publication:</span>
      </p>
      <span style='font-size: 14px;'>
      <p>
      [1] <b>R. Luo</b>, D, Berenson, A Framework for Unsupervised Online Human Reaching Motion Recognition and Early Prediction, in <span style="font-style:italic">IROS</span> 2015. <a href="files/Luo15iros.pdf">[PDF]</a>
      </p>
      <p>
      [2] R. Hayne, <b>R. Luo</b>, D. Berenson, Considering avoidance and consistency in motion planning for human-robot manipulation in a shared workspace, in <span style="font-style:italic">ICRA</span>, 2016. <a href="files/Luo16icra.pdf">[PDF]</a>
      </p>
      <p>
      [3] <b>R. Luo</b>, D, Berenson, Unsupervised early prediction of human reaching for human–robot collaboration in shared workspaces, in <span style="font-style:italic">Autonomous Robots</span> 2017. <a href="files/Luo2018_Article_UnsupervisedEarlyPredictionOfH.pdf">[PDF]</a>
      </p>
      </span>
    </div>
  </div>

</div>
<br/>

<div class="container">
    <h2 id="publications">Publications (J: Journal C: Conference W: Workshop)</h2>
  <hr/>
    <div class="row">
    <div class="col-md-12">
            <ul style="list-style-type: none; padding-left: 0" >
              <li>[J] <b>R. Luo*</b>, Y. Weng*, Y. Wang, P. Jayakumar, M. J. Brudnak, V. Paul, V. R. Desaraju, J. L. Stein, T. Ersal, X. J. Yang, A Workload Adaptive Haptic Shared Control Scheme for Semi-Autonomous Driving. in <span style="font-style:italic">Transactions On Human-Machine Systems</span>. [<em>In Preparation</em>]</li>
              <li>[J] <b>R. Luo</b>, N. Du, K. Y. Huang, X. J. Yang, Enhancing autonomy transparency: an option-centric rationale approach, in <span style="font-style:italic">Journal of Cognitive Engineering and Decision Making</span> 2019. [<em>In Preparation</em>]</li>
              <li>[J] <b>R. Luo</b>, D, Berenson, Unsupervised early prediction of human reaching for human–robot collaboration in shared workspaces, in <span style="font-style:italic">Autonomous Robots</span> 2017. <a href="files/Luo2018_Article_UnsupervisedEarlyPredictionOfH.pdf">[PDF]</a></li>
              <li>[J] J. Xu, S. Liu, A. Wan, B. Gao, Q. Yi, D. Zhao, <b>R. Luo</b>, K. Chen, An absolute phase technique for 3D profile measurement using four-step structured light pattern, in <span style="font-style:italic">Optics and Lasers in Engineering</span> 2012.</li>
            <br/>
              <li>[C] <b>R. Luo*</b>, Y. Wang*, Y. Weng, V. Paul, M. J. Brudnak, P. Jayakumar, M. Reed, J. L. Stein, T. Ersal, X. J. Yang, Toward Real-time Assessment of Workload: A Bayesian Inference Approach, in <span style="font-style:italic">HFES</span> 2019. <a href="files/HFES2019_Bayesion_inference_workload_estimation.pdf">[PDF]</a></li>
              <li>[C] <b>R. Luo</b>, N. Du, K. Y. Huang, X. J. Yang, Enhancing Transparency in Human-autonomy Teaming via the Option-centric Rationale Display, in <span style="font-style:italic">HFES</span> 2019. <a href="files/HFES2019_Explanation_AI.pdf">[PDF]</a> </li>
              <li>[C] <b>R. Luo</b>, D, Berenson, A Framework for Unsupervised Online Human Reaching Motion Recognition and Early Prediction, in <span style="font-style:italic">IROS</span> 2015. <a href="files/Luo15iros.pdf">[PDF]</a></li>
              <li>[C] R. Hayne, <b>R. Luo</b>, D. Berenson, Considering avoidance and consistency in motion planning for human-robot manipulation in a shared workspace, in <span style="font-style:italic">ICRA</span>, 2016. <a href="files/Luo16icra.pdf">[PDF]</a></li>
              <li>[C] <b>R. Luo</b>, N. Chakraborty, K. Sycara, Supervisory control for cost-effective redistribution of robotic swarms, in <span style="font-style:italic">SMC</span>, 2014. <a href="files/Luo14smc.pdf">[PDF]</a> (<b>Best student paper finalist</b>)</li>
            <br/>
              <li>[W] <b>R. Luo</b>, S. Benge, N. Vasher, G. VanderVliet, J. Turner, M. Ghaffari, X. J. Yang, Toward an Interactive Robot Docent: Estimating Museum Visitors’ Comfort Level with Art, in <span style="font-style:italic">RSS workshop</span>, 2019. <a href="files/Luo19rss_workshop.pdf">[PDF]</a></li>
              <li>[W] <b>R. Luo</b>, D. Berenson, Learning Controller Success Rate for an <em>SE(2)</em> Robot in Contact-Rich Environments, in <span style="font-style:italic">RSS workshop</span>, 2017. <a href="files/Luo17rss_workshop.pdf">[PDF]</a></li>

            </ul>
    </div>
    </div>

</div>

<br/>

<div class="container">
    <h2 id="service">Service</h2>
  <hr/>
  Reviewer for ICRA, IROS, RAL, ACC, WAFR, Humanoids
</div>

<br/>
<div class="container">
    <h2 id="award">Awards</h2>
  <hr/>
    <div class="row">
    <div class="col-md-12">
      <ul style="list-style-type: none; padding-left: 0" >
        <li>HFES 2019 Student Presenter Award</li>
        <li>IROS 2015 NSF Travel Award</li>
        <li>SMC 2014 Student Travel Award</li>
        <li>SMC 2014 Best Student Paper Finalist</li>
        <li>2014-2015 RBE Fellowship, WPI</li>
      </ul>
    </div>
    </div>
</div>


<footer class="navbar-default">
  <div class="container text-center">
    <p class="text-muted credit" style="color:#b0b0b0;font-size:14px">
      Last Update: Oct 2019. &copy;Ruikun Luo. Powered by Bootstrap, Font Awesome, and Academicons.
    </p>
  </div>
</footer>


</body>

</html>
